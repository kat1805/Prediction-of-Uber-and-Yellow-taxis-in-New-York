{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "from urllib.request import urlretrieve\n",
    "import os\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making data directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code adapted from MAST30034 Tutorial 1\n",
    "# from the current `tute_1` directory, go back two levels to the `MAST30034` directory\n",
    "output_relative_dir = '../data/raw/'\n",
    "\n",
    "# check if it exists as it makedir will raise an error if it does exist\n",
    "if not os.path.exists(output_relative_dir):\n",
    "    os.makedirs(output_relative_dir)\n",
    "\n",
    "# Define the directory names\n",
    "main_dirs = ['raw_train', 'raw_test']\n",
    "taxi_type_dir = ['yellow', 'FHVHV']\n",
    "\n",
    "# now, for each type of data set we will need, we will create the paths\n",
    "for target_dir in main_dirs: # taxi_zones should already exist\n",
    "    if not os.path.exists(output_relative_dir + target_dir):\n",
    "        os.makedirs(output_relative_dir + target_dir)\n",
    "\n",
    "# Contruct the path strings\n",
    "final_output_train_dir = ''\n",
    "final_output_test_dir = ''\n",
    "final_output_train_dir = output_relative_dir  + main_dirs[0] + '/'\n",
    "final_output_test_dir = output_relative_dir + main_dirs[1] + '/'\n",
    "\n",
    "# Make new directories if the desired directory name is not present\n",
    "for maindirs in main_dirs:\n",
    "    if maindirs == main_dirs[0]:\n",
    "        for sub_target_dir in taxi_type_dir:\n",
    "            if not os.path.exists(final_output_train_dir + sub_target_dir):\n",
    "                os.makedirs(final_output_train_dir + sub_target_dir)\n",
    "    else:\n",
    "        for sub_target_dir in taxi_type_dir:\n",
    "            if not os.path.exists(final_output_test_dir + sub_target_dir):\n",
    "                os.makedirs(final_output_test_dir + sub_target_dir)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the raw training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the train  data range\n",
    "YEAR_TRAIN = '2021'\n",
    "MONTHS_TRAIN_DATA = range(1,13)\n",
    "\n",
    "\n",
    "# Yellow and HVFHV URLs\n",
    "URL_YELLOW_TAXI = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata\"#2021-01.parquet\n",
    "URL_FHVHV = \"https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata\"#2021-01.parquet\n",
    "\n",
    "\n",
    "# Making the directory paths\n",
    "output_dir_raw_train_yellow = final_output_train_dir + taxi_type_dir[0]\n",
    "output_dir_raw_train_FHVHV = final_output_train_dir + taxi_type_dir[1]\n",
    "output_dir_raw_test_yellow = final_output_test_dir + taxi_type_dir[0]\n",
    "output_dir_raw_test_FHVHV = final_output_test_dir + taxi_type_dir[1]\n",
    "\n",
    "#Downloading raw train data\n",
    "for URL in (URL_YELLOW_TAXI, URL_FHVHV):\n",
    "\n",
    "    # Downloading the training data for the yellow\n",
    "    if URL == URL_YELLOW_TAXI:\n",
    "        for month in MONTHS_TRAIN_DATA:\n",
    "            if month < 10:\n",
    "                month = str(month).zfill(2)\n",
    "            else:\n",
    "\n",
    "            # generate url\n",
    "            url = f'{URL}_{YEAR_TRAIN}-{month}.parquet'\n",
    "     \n",
    "            # generate output location and filename\n",
    "            output_dir = f\"{output_dir_raw_train_yellow}/{YEAR_TRAIN}-{month}.parquet\"\n",
    "          \n",
    "            # download\n",
    "            urlretrieve(url, output_dir) \n",
    "\n",
    "    # Download the training data for HVFHV\n",
    "    else:\n",
    "        for month in MONTHS_TRAIN_DATA:\n",
    "        \n",
    "            if month < 10:\n",
    "                month = str(month).zfill(2)\n",
    "            else:\n",
    "            # generate url\n",
    "            url = f'{URL}_{YEAR_TRAIN}-{month}.parquet'\n",
    "       \n",
    "            # generate output location and filename\n",
    "            output_dir = f\"{output_dir_raw_train_FHVHV}/{YEAR_TRAIN}-{month}.parquet\"\n",
    "       \n",
    "            # download\n",
    "            urlretrieve(url, output_dir) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the raw testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the test data range\n",
    "YEAR_TEST = '2022'\n",
    "MONTHS_TEST_DATA = range(1,5)\n",
    "\n",
    "# Making the directory paths\n",
    "output_dir_raw_test_yellow = final_output_test_dir + taxi_type_dir[0]\n",
    "output_dir_raw_test_FHVHV = final_output_test_dir + taxi_type_dir[1]\n",
    "\n",
    "\n",
    "# Downloading raw test data\n",
    "for URL in (URL_YELLOW_TAXI, URL_FHVHV):\n",
    "\n",
    "    # Yellow taxi test data\n",
    "    if URL == URL_YELLOW_TAXI:\n",
    "        for month in MONTHS_TEST_DATA:\n",
    "            # 0-fill i.e 1 -> 01, 2 -> 02, etc\n",
    "            if month < 10:\n",
    "                month = str(month).zfill(2)\n",
    "            else:\n",
    "           \n",
    "            # generate url\n",
    "            url = f'{URL}_{YEAR_TEST}-{month}.parquet'\n",
    "      \n",
    "            # generate output location and filename\n",
    "            output_dir = f\"{output_dir_raw_test_yellow}/{YEAR_TEST}-{month}.parquet\"\n",
    "          \n",
    "            # download\n",
    "            urlretrieve(url, output_dir) \n",
    "      \n",
    "    else:\n",
    "        for month in MONTHS_TEST_DATA:\n",
    "            # 0-fill i.e 1 -> 01, 2 -> 02, etc\n",
    "            if month < 10:\n",
    "                month = str(month).zfill(2)  \n",
    "            else:\n",
    "            # generate url\n",
    "            url = f'{URL}_{YEAR_TEST}-{month}.parquet'\n",
    "           \n",
    "            # generate output location and filename\n",
    "            output_dir = f\"{output_dir_raw_test_FHVHV}/{YEAR_TEST}-{month}.parquet\"\n",
    "          \n",
    "            # download\n",
    "            urlretrieve(url, output_dir) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the geospatial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../data/raw/nyc.zip', <http.client.HTTPMessage at 0x7fb150dcbeb0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downloading the geospatial data \n",
    "\n",
    "URL_LOOKUP = \"https://d37ci6vzurychx.cloudfront.net/misc/taxi+_zone_lookup.csv\"\n",
    "URL_SHAPE = \"https://d37ci6vzurychx.cloudfront.net/misc/taxi_zones.zip\"\n",
    "\n",
    "# Define the file names\n",
    "output_csv = \"../data/raw/nyc.csv\"\n",
    "output_zip = \"../data/raw/nyc.zip\"\n",
    "\n",
    "# Download the data\n",
    "urlretrieve(URL_LOOKUP, output_csv) \n",
    "urlretrieve(URL_SHAPE, output_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the zip file of the geospatial data\n",
    "\n",
    "# specifying the zip file name\n",
    "file_name = \"../data/raw/nyc.zip\"\n",
    "  \n",
    "# opening the zip file in READ mode\n",
    "with ZipFile(file_name, 'r') as zip:\n",
    "    # extracting all the files\n",
    "    zip.extractall(path = \"../data/raw/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the Covid-19 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading the Covid-19 data\n",
    "\n",
    "url_covid = \"https://health.data.ny.gov/api/views/xdss-u53e/rows.csv?accessType=DOWNLOAD\"\n",
    "\n",
    "# generate output location and filename\n",
    "output_dir = \"../data/raw/covid_county.csv\"\n",
    "\n",
    "# download\n",
    "urlretrieve(url_covid, output_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading the geospatial data for the NYC's 5 boroughs\n",
    "\n",
    "# Define the URL\n",
    "borough_boundaries_url = \"https://data.cityofnewyork.us/api/geospatial/tqmj-j8zm?method=export&format=Shapefile\"\n",
    "\n",
    "# generate output location and filename\n",
    "output_dir = \"../data/raw/borough_boundaries.zip\"\n",
    "\n",
    "# download\n",
    "urlretrieve(borough_boundaries_url, output_dir) \n",
    "\n",
    "# Extracting the zip file\n",
    "file_name = \"../data/raw/borough_boundaries.zip\"\n",
    "with ZipFile(file_name, 'r') as zip:\n",
    "    # extracting all the files\n",
    "    zip.extractall(path = \"../data/raw/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "afcda84b7471a9b9fde108a34f159f021985318d3feb99cad4970c959fa9ac9e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
